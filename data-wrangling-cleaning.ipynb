{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.dsm2_reader import read_scenario_dir\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from data_config import gatef, elev_list, flow_list, stn_name\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_list = ['MID_GATEOP','GLC_GATEOP','OLD_GATEOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mathing:\t\tC:\\Users\\Inigo\\Projects\\sdg-dashboard\\data\\output\\FPV1Ma_hydro_7.dss <----> C:\\Users\\Inigo\\Projects\\sdg-dashboard\\data\\output\\FPV1Ma_SDG_7.dss\n",
      "mathing:\t\tC:\\Users\\Inigo\\Projects\\sdg-dashboard\\data\\output\\FPV2Ma_hydro_7.dss <----> C:\\Users\\Inigo\\Projects\\sdg-dashboard\\data\\output\\FPV2Ma_SDG_7.dss\n",
      "DSS file opened successfully.\n",
      "DSS file opened successfully.\n",
      "DSS file opened successfully.\n",
      "DSS file opened successfully.\n"
     ]
    }
   ],
   "source": [
    "data = read_scenario_dir(\"C:/Users/Inigo/Projects/sdg-dashboard/data\", v7_filter=\"_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV1Ma_hydro_7.dss', 'C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV2Ma_hydro_7.dss'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vel(flow,stage_up, bottom_elev, width):\n",
    "    #velocity is flow/cross-section\n",
    "    \n",
    "    xs = (stage_up-bottom_elev)*width\n",
    "    vel = flow/xs\n",
    "    return vel\n",
    "\n",
    "def filter_data(data, column, values, start_date=None, end_date=None):\n",
    "    \"\"\"Filter data based on a column and a list of values.\"\"\"\n",
    "    if start_date:\n",
    "        data = data[data[column].isin(values)].dropna()\n",
    "        data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n",
    "    else:\n",
    "        data = data[data[column].isin(values)].dropna()\n",
    "    return data\n",
    "\n",
    "def rename_gates(data, column, rename_map):\n",
    "    \"\"\"Rename values in a column in the DataFrame.\"\"\"\n",
    "    data[column] = data[column].replace(rename_map)\n",
    "    return data\n",
    "\n",
    "def set_datetime_index(data):\n",
    "    data.set_index('datetime', inplace=True)\n",
    "    data = data['value']\n",
    "    return(data)\n",
    "\n",
    "\n",
    "# def filter_date(data, start_date, end_date):\n",
    "#     return data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n",
    "\n",
    "# def get_gate_up(data, column)\n",
    "\n",
    "def prepare_full_data(sdg_flow, sdg_stage, sdg_gateop, hydro_wl, gatef):\n",
    "    \"\"\"\n",
    "    Prepare gate data dictionary from input datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - sdg_flow: DataFrame with flow data.\n",
    "    - sdg_stage: DataFrame with stage data.\n",
    "    - gatop: DataFrame with gate operation data.\n",
    "    - hydro_wl: Dataframe with water level data.\n",
    "    - gatef: DataFrame containing gate configuration.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing gate data.\n",
    "    \"\"\"\n",
    "    full_data = {}\n",
    "    for i, gate_name in enumerate(gatef['name']):\n",
    "        flow_data = filter_data(sdg_flow, 'gate_op', [gatef[\"flow_op\"][i]])\n",
    "        gate_data = filter_data(sdg_stage, 'gate_op', [gatef['gate_status'][i]])\n",
    "        gate_data = gate_data[gate_data['unit'] == \"FEET\"]\n",
    "        gateop_data = sdg_gateop[sdg_gateop['gate_op']==gatef['station'][i]]\n",
    "        hydro_wl_data = hydro_wl[hydro_wl['gate']==gatef['station'][i]]\n",
    "        full_data[gatef[\"ID\"][i]] = {\n",
    "            'name': gatef['name'][i],\n",
    "            'bottom_elev': gatef['bottom_elev'][i],\n",
    "            'width': gatef['width'][i],\n",
    "            'flow_data': flow_data, #sc2_flow\n",
    "            'gate_data': gate_data, #sc2_gate\n",
    "            'gate_operation_data': gateop_data, #sc2_gateop\n",
    "            \"water_level_data\": hydro_wl_data #sc2_wl\n",
    "            \n",
    "        }\n",
    "    return full_data\n",
    "\n",
    "def generate_full_model_data(data, path, gatef, elev_list, flow_list, stn_name, stn_list, start_date=None, end_date=None):\n",
    "    sdg = data[path]['sdg']\n",
    "    hydro = data[path]['hydro']\n",
    "\n",
    "    sdg_stage = filter_data(sdg, 'gate_op', elev_list, start_date, end_date)\n",
    "    sdg_flow = filter_data(sdg, 'gate_op', flow_list, start_date, end_date)\n",
    "    sdg_gateop = filter_data(sdg, 'gate_op', stn_list, start_date, end_date)\n",
    "    gate_names = {'MID_GATEOP': 'MHO', 'GLC_GATEOP': 'DGL', 'OLD_GATEOP': 'OLD'}\n",
    "    sdg_gateop = rename_gates(sdg_gateop, \"gate_op\", gate_names)\n",
    "    \n",
    "    hydro_wl = hydro[hydro['parameter']==\"STAGE\"]\n",
    "    hydro_wl = filter_data(hydro_wl, 'gate', stn_name, start_date, end_date)\n",
    "\n",
    "    full_data = prepare_full_data(sdg_flow, sdg_stage, sdg_gateop, hydro_wl, gatef)\n",
    "    \n",
    "    sdg_flow_GLC_FLOW_FISH = set_datetime_index(full_data['GLC']['flow_data'])\n",
    "    sdg_flow_GLC_GATE_UP = set_datetime_index(full_data['GLC']['gate_data'])\n",
    "    glc_bottom_elev = full_data['GLC']['bottom_elev']\n",
    "    glc_width = full_data['GLC']['width']\n",
    "\n",
    "\n",
    "    sdg_flow_MID_FLOW_FISH = set_datetime_index(full_data['MID']['flow_data'])\n",
    "    sdg_flow_MID_GATE_UP = set_datetime_index(full_data['MID']['gate_data'])\n",
    "    mid_bottom_elev = full_data['MID']['bottom_elev']\n",
    "    mid_width = full_data['MID']['width']\n",
    "    \n",
    "    sdg_flow_OLD_FLOW_FISH = set_datetime_index(full_data['OLD']['flow_data'])\n",
    "    sdg_flow_OLD_GATE_UP = set_datetime_index(full_data['OLD']['gate_data'])\n",
    "    old_bottom_elev = full_data['OLD']['bottom_elev']\n",
    "    old_width = full_data['OLD']['width']\n",
    "    \n",
    "    full_data[\"GLC\"]['vel'] = pd.DataFrame(calc_vel(sdg_flow_GLC_FLOW_FISH,sdg_flow_GLC_GATE_UP,glc_bottom_elev, glc_width))\n",
    "    full_data[\"MID\"]['vel'] = pd.DataFrame(calc_vel(sdg_flow_MID_FLOW_FISH,sdg_flow_MID_GATE_UP,mid_bottom_elev, mid_width))\n",
    "    full_data[\"OLD\"]['vel'] = pd.DataFrame(calc_vel(sdg_flow_OLD_FLOW_FISH,sdg_flow_OLD_GATE_UP,old_bottom_elev, old_width))\n",
    "\n",
    "    for key in [\"GLC\", \"MID\", \"OLD\"]:\n",
    "        full_data[key]['vel']['datetime'] = full_data[key]['vel'].index\n",
    "        full_data[key]['vel'] = full_data[key]['vel'].reset_index(drop=True)\n",
    "        full_data[key]['vel'] = full_data[key]['vel'][[\"datetime\", \"value\"]]\n",
    "    \n",
    "    return full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_zoom = '2016-05-01'\n",
    "end_zoom = '2016-11-30'\n",
    "fpv1ma_hydro_full_data = generate_full_model_data(data, \n",
    "                 'C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV1Ma_hydro_7.dss', \n",
    "                 gatef,\n",
    "                 elev_list,\n",
    "                 flow_list,\n",
    "                 stn_name,\n",
    "                 stn_list,\n",
    "                 start_zoom,\n",
    "                 end_zoom\n",
    "                 )\n",
    "\n",
    "fpv2ma_hydro_full_data = generate_full_model_data(data,\n",
    "                              'C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV2Ma_hydro_7.dss',\n",
    "                              gatef,\n",
    "                              elev_list,\n",
    "                              flow_list,\n",
    "                              stn_name,\n",
    "                              stn_list,\n",
    "                              start_zoom,\n",
    "                            end_zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-01 00:00:00</td>\n",
       "      <td>-0.540797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-01 00:15:00</td>\n",
       "      <td>-0.582787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-01 00:30:00</td>\n",
       "      <td>-0.613909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-01 00:45:00</td>\n",
       "      <td>-0.598160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-01 01:00:00</td>\n",
       "      <td>-0.601773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20444</th>\n",
       "      <td>2016-11-29 23:00:00</td>\n",
       "      <td>9.362068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20445</th>\n",
       "      <td>2016-11-29 23:15:00</td>\n",
       "      <td>9.657503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20446</th>\n",
       "      <td>2016-11-29 23:30:00</td>\n",
       "      <td>9.941912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20447</th>\n",
       "      <td>2016-11-29 23:45:00</td>\n",
       "      <td>10.228580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20448</th>\n",
       "      <td>2016-11-30 00:00:00</td>\n",
       "      <td>10.457363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime      value\n",
       "0     2016-05-01 00:00:00  -0.540797\n",
       "1     2016-05-01 00:15:00  -0.582787\n",
       "2     2016-05-01 00:30:00  -0.613909\n",
       "3     2016-05-01 00:45:00  -0.598160\n",
       "4     2016-05-01 01:00:00  -0.601773\n",
       "...                   ...        ...\n",
       "20444 2016-11-29 23:00:00   9.362068\n",
       "20445 2016-11-29 23:15:00   9.657503\n",
       "20446 2016-11-29 23:30:00   9.941912\n",
       "20447 2016-11-29 23:45:00  10.228580\n",
       "20448 2016-11-30 00:00:00  10.457363\n",
       "\n",
       "[20449 rows x 2 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fpv2ma_hydro_full_data[\"OLD\"][\"vel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_gateop(model_data, gate):\n",
    "    gate_up_df = model_data[gate]['gate_operation_data'][[\"datetime\", \"value\"]]\n",
    "    gate_up_df[\"gate_status\"] = gate_up_df['value']>=10\n",
    "    gate_up_df['consecutive_groups'] = (gate_up_df['value'] != gate_up_df['value'].shift()).cumsum()\n",
    "    gate_up_df['min_datetime'] = gate_up_df.groupby('consecutive_groups')['datetime'].transform('min')\n",
    "    gate_up_df['max_datetime'] = gate_up_df.groupby('consecutive_groups')['datetime'].transform('max')\n",
    "    consecutive_streaks = gate_up_df.groupby(['consecutive_groups', 'value', 'min_datetime', 'max_datetime']).size().reset_index(name='count')\n",
    "    consecutive_streaks['streak_duration'] = consecutive_streaks['count'] * 15 / 60\n",
    "    consecutive_streaks_clean = consecutive_streaks.drop(['value', 'consecutive_groups', 'max_datetime'], axis = 1)\n",
    "    # print(consecutive_streaks_clean.head())\n",
    "    merged_gate_df = pd.merge(gate_up_df, consecutive_streaks_clean,left_on=\"min_datetime\", right_on=\"min_datetime\")\n",
    "    merged_gate_df = merged_gate_df.drop(['consecutive_groups', 'value'], axis=1)\n",
    "    merged_gate_df = merged_gate_df.rename(columns={\"min_datetime\": \"gate_min_datetime\", \n",
    "                                                \"max_datetime\": \"gate_max_datetime\",\n",
    "                                                \"count\": \"gate_count\",\n",
    "                                                \"streak_duration\": \"gate_streak_duration\"})\n",
    "    return merged_gate_df\n",
    "\n",
    "def post_process_velocity(model_data, gate):\n",
    "    vel_zoom_df =model_data[gate][\"vel\"]\n",
    "    vel_zoom_df['Velocity_Category'] = np.where(vel_zoom_df['value'] >= 8, \"Over 8ft/s\", \"Under 8ft/s\")\n",
    "    #.shift shift value down and compare each value with the previous row; increase value when rows are different\n",
    "    vel_zoom_df['consecutive_groups'] = (vel_zoom_df['Velocity_Category'] != vel_zoom_df['Velocity_Category'].shift()).cumsum()\n",
    "    vel_zoom_df['min_datetime'] = vel_zoom_df.groupby('consecutive_groups')['datetime'].transform('min')\n",
    "    vel_zoom_df['max_datetime'] = vel_zoom_df.groupby('consecutive_groups')['datetime'].transform('max')\n",
    "    vel_zoom_df['date'] = vel_zoom_df['datetime'].dt.date.astype(str)\n",
    "    consecutive_streaks_vel = vel_zoom_df.groupby(['consecutive_groups', 'Velocity_Category', 'min_datetime', 'max_datetime']).size().reset_index(name='count')\n",
    "    consecutive_streaks_vel['streak_duration'] = consecutive_streaks_vel['count'] * 15 / 60\n",
    "\n",
    "    consecutive_streaks_vel_clean = consecutive_streaks_vel.drop(['consecutive_groups', 'Velocity_Category', 'max_datetime'], axis=1)\n",
    "    merged_vel_df = pd.merge(vel_zoom_df, consecutive_streaks_vel_clean,left_on=\"min_datetime\", right_on=\"min_datetime\")\n",
    "\n",
    "    return merged_vel_df\n",
    "\n",
    "def post_process_full_data(model_data, gate):\n",
    "    merged_gate_df = post_process_gateop(model_data, gate)\n",
    "    merged_vel_df = post_process_velocity(model_data, gate)\n",
    "    full_merged_df = pd.merge(merged_vel_df, merged_gate_df, left_on=\"datetime\", right_on=\"datetime\")\n",
    "    full_merged_df['time_unit'] = 0.25\n",
    "    \n",
    "    return full_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime     value Velocity_Category  consecutive_groups  \\\n",
      "0 2016-05-01 00:00:00 -0.394567       Under 8ft/s                   1   \n",
      "1 2016-05-01 00:15:00 -0.444881       Under 8ft/s                   1   \n",
      "2 2016-05-01 00:30:00 -0.452719       Under 8ft/s                   1   \n",
      "3 2016-05-01 00:45:00 -0.467519       Under 8ft/s                   1   \n",
      "4 2016-05-01 01:00:00 -0.465833       Under 8ft/s                   1   \n",
      "\n",
      "  min_datetime        max_datetime        date  count  streak_duration  \\\n",
      "0   2016-05-01 2016-05-01 05:00:00  2016-05-01     21             5.25   \n",
      "1   2016-05-01 2016-05-01 05:00:00  2016-05-01     21             5.25   \n",
      "2   2016-05-01 2016-05-01 05:00:00  2016-05-01     21             5.25   \n",
      "3   2016-05-01 2016-05-01 05:00:00  2016-05-01     21             5.25   \n",
      "4   2016-05-01 2016-05-01 05:00:00  2016-05-01     21             5.25   \n",
      "\n",
      "   gate_status gate_min_datetime   gate_max_datetime  gate_count  \\\n",
      "0        False        2016-05-01 2016-05-01 03:45:00          16   \n",
      "1        False        2016-05-01 2016-05-01 03:45:00          16   \n",
      "2        False        2016-05-01 2016-05-01 03:45:00          16   \n",
      "3        False        2016-05-01 2016-05-01 03:45:00          16   \n",
      "4        False        2016-05-01 2016-05-01 03:45:00          16   \n",
      "\n",
      "   gate_streak_duration  time_unit  \n",
      "0                   4.0       0.25  \n",
      "1                   4.0       0.25  \n",
      "2                   4.0       0.25  \n",
      "3                   4.0       0.25  \n",
      "4                   4.0       0.25  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inigo\\AppData\\Local\\Temp\\ipykernel_53388\\2315908888.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gate_up_df[\"gate_status\"] = gate_up_df['value']>=10\n",
      "C:\\Users\\Inigo\\AppData\\Local\\Temp\\ipykernel_53388\\2315908888.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gate_up_df['consecutive_groups'] = (gate_up_df['value'] != gate_up_df['value'].shift()).cumsum()\n"
     ]
    }
   ],
   "source": [
    "full_data = post_process_full_data(fpv2ma_hydro_full_data, \"GLC\")\n",
    "print(full_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_up = post_process_gateop(fpv2ma_hydro_full_data, \"MID\")\n",
    "vel_zoom_df =fpv2ma_hydro_full_data[\"GLC\"][\"vel\"]\n",
    "# vel_zoom_df['datetime'] = vel_zoom_df.index\n",
    "# vel_zoom_df = vel_zoom_df.reset_index(drop=True) \n",
    "# print(gate_up.head()) # fpv2ma_hydro_full_data['GLC']['gate_operation_data']\n",
    "vel_zoom_df['Velocity_Category'] = np.where(vel_zoom_df['value'] >= 8, \"Over 8ft/s\", \"Under 8ft/s\")\n",
    "#.shift shift value down and compare each value with the previous row; increase value when rows are different\n",
    "vel_zoom_df['consecutive_groups'] = (vel_zoom_df['Velocity_Category'] != vel_zoom_df['Velocity_Category'].shift()).cumsum()\n",
    "# print(vel_zoom_df)\n",
    "vel_zoom_df['min_datetime'] = vel_zoom_df.groupby('consecutive_groups')['datetime'].transform('min')\n",
    "vel_zoom_df['max_datetime'] = vel_zoom_df.groupby('consecutive_groups')['datetime'].transform('max')\n",
    "vel_zoom_df['date'] = vel_zoom_df['datetime'].dt.date.astype(str)\n",
    "consecutive_streaks_vel = vel_zoom_df.groupby(['consecutive_groups', 'Velocity_Category', 'min_datetime', 'max_datetime']).size().reset_index(name='count')\n",
    "consecutive_streaks_vel['streak_duration'] = consecutive_streaks_vel['count'] * 15 / 60\n",
    "\n",
    "consecutive_streaks_vel_clean = consecutive_streaks_vel.drop(['consecutive_groups', 'Velocity_Category', 'max_datetime'], axis=1)\n",
    "merged_df = pd.merge(vel_zoom_df, consecutive_streaks_vel_clean,left_on=\"min_datetime\", right_on=\"min_datetime\")\n",
    "# print(merged_df.head(5))\n",
    "# over_streaks = consecutive_streaks_vel[consecutive_streaks_vel['Velocity_Category'] == 'Over 8ft/s']\n",
    "# under_streaks = consecutive_streaks_vel[consecutive_streaks_vel['Velocity_Category'] == 'Under 8ft/s']\n",
    "\n",
    "# # Total duration for over and under 8ft/s\n",
    "# total_over_duration = over_streaks['count'].sum()\n",
    "# total_under_duration = under_streaks['count'].sum()\n",
    "\n",
    "# over_streak_duration =  over_streaks['count'] * 15 / 60\n",
    "# under_streak_duration = under_streaks['count'] * 15 / 60\n",
    "\n",
    "# # Group by the Velocity Category and count the number of days in each category\n",
    "# vel_count_df = vel_zoom_df.groupby('Velocity_Category').size().reset_index(name='count')\n",
    "\n",
    "# total_time_df = pd.DataFrame({\n",
    "#     'Velocity_Category': ['Over 8ft/s', 'Under 8ft/s'],\n",
    "#     'Total Hours': [total_over_duration * 15 / 60, total_under_duration * 15 / 60]\n",
    "# })\n",
    "\n",
    "# consecutive_streaks_vel.rename(columns={\n",
    "#     \"Velocity_Category\": \"Status\"},\n",
    "#     inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         min_datetime  count  streak_duration\n",
      "0 2016-05-01 00:00:00     21             5.25\n",
      "1 2016-05-01 05:15:00     19             4.75\n",
      "2 2016-05-01 10:00:00     22             5.50\n",
      "3 2016-05-01 15:30:00     31             7.75\n",
      "4 2016-05-01 23:15:00     24             6.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(consecutive_streaks_vel_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inigo\\AppData\\Local\\Temp\\ipykernel_53388\\599939783.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sdg_gateop['gate_op'] = sdg_gateop['gate_op'].replace(gate_names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  value  unit gate_op scenario\n",
      "0 2015-12-31 00:15:00    NaN  FEET     DGL   FPV1MA\n",
      "1 2015-12-31 00:30:00    NaN  FEET     DGL   FPV1MA\n",
      "2 2015-12-31 00:45:00    NaN  FEET     DGL   FPV1MA\n",
      "3 2015-12-31 01:00:00    NaN  FEET     DGL   FPV1MA\n",
      "4 2015-12-31 01:15:00    NaN  FEET     DGL   FPV1MA\n",
      "                 datetime     value  unit        gate_op scenario\n",
      "11711 2016-05-01 00:00:00  3.680600  FEET  GLC_GATE_DOWN   FPV1MA\n",
      "11712 2016-05-01 00:15:00  3.818419  FEET  GLC_GATE_DOWN   FPV1MA\n",
      "11713 2016-05-01 00:30:00  3.946771  FEET  GLC_GATE_DOWN   FPV1MA\n",
      "11714 2016-05-01 00:45:00  4.091312  FEET  GLC_GATE_DOWN   FPV1MA\n",
      "11715 2016-05-01 01:00:00  4.218915  FEET  GLC_GATE_DOWN   FPV1MA\n"
     ]
    }
   ],
   "source": [
    "sdg = data['C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV1Ma_hydro_7.dss']['sdg']\n",
    "sdg_stage = sdg[sdg['gate_op'].isin(elev_list)]\n",
    "sdg_flow = sdg[sdg['gate_op'].isin(flow_list)]\n",
    "sdg_gateop = sdg[sdg['gate_op'].isin(stn_list)]\n",
    "gate_names = {'MID_GATEOP':'MHO',\n",
    "              'GLC_GATEOP':'DGL',\n",
    "              'OLD_GATEOP':'OLD'}\n",
    "sdg_gateop['gate_op'] = sdg_gateop['gate_op'].replace(gate_names)\n",
    "print(sdg_gateop.head())\n",
    "year = \"2012\"\n",
    "\n",
    "# sdg_gateop =filter_date(sdg_gateop, start_zoom, end_zoom)\n",
    "print(sdg_gateop.head())\n",
    "hydro = data['C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV1Ma_hydro_7.dss']['hydro']\n",
    "hydro_wl = hydro[hydro['parameter']==\"STAGE\"]\n",
    "hydro_wl = hydro_wl[hydro_wl['gate'].isin(stn_name)]\n",
    "# print(hydro_wl.head())\n",
    "\n",
    "# print(wl.head())\n",
    "# print(data['C:\\\\Users\\\\Inigo\\\\Projects\\\\sdg-dashboard\\\\data\\\\output\\\\FPV1Ma_hydro_7.dss'].keys())\n",
    "# # hydro_gateop.rename(columns={'MID_GATEOP':'MHO','GLC_GATEOP':'DGL','OLD_GATEOP':'OLD'}, inplace=True) # renaming to make it easier later.\n",
    "# print(hydro_gateop['gate'].unique())\n",
    "# print(hydro_gateop[hydro_gateop['gate']==\"DGL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = {}\n",
    "\n",
    "for i, gate_name in enumerate(gatef['name']):\n",
    "\n",
    "    flow_data = sdg_flow[sdg_flow.gate_op == gatef[\"flow_op\"][i]]\n",
    "    gate_data = sdg_stage[sdg_stage.gate_op== gatef['gate_status'][i]]\n",
    "     \n",
    "    # Drop rows with NaN values from flow_data and gate_data\n",
    "    flow_data = flow_data.dropna()\n",
    "    gate_data = gate_data.dropna()\n",
    "    \n",
    "    full_data[gatef[\"ID\"][i]] = {\n",
    "        'name': gatef['name'][i],\n",
    "        'bottom_elev': gatef['bottom_elev'][i],\n",
    "        'width': gatef['width'][i],\n",
    "        'flow_data': flow_data,\n",
    "        'gate_data': gate_data\n",
    "    }\n",
    "sdg_flow_GLC_FLOW_FISH = full_data['GLC']['flow_data']\n",
    "sdg_flow_GLC_GATE_UP = full_data['GLC']['gate_data']\n",
    "glc_bottom_elev = full_data['GLC']['bottom_elev']\n",
    "glc_width = full_data['GLC']['width']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_flow_MID_FLOW_FISH = full_data['MID']['flow_data']['value']\n",
    "sdg_flow_MID_GATE_UP = full_data['MID']['gate_data']['value']\n",
    "mid_bottom_elev = full_data['MID']['bottom_elev']\n",
    "mid_width = full_data['MID']['width']\n",
    "\n",
    "sdg_flow_OLD_FLOW_FISH = full_data['OLD']['flow_data']['value']\n",
    "sdg_flow_OLD_GATE_UP = full_data['OLD']['gate_data']['value']\n",
    "old_bottom_elev = full_data['OLD']['bottom_elev']\n",
    "old_width = full_data['OLD']['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Addition/subtraction of integers and integer-arrays with DatetimeArray is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# mask = (sdg_flow.index.month>=5) & (sdg_flow.index.month<12) # time when gate are in operation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# vel=pd.DataFrame()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# sdg_flow_GLC_FLOW_FISH.set_index('datetime', inplace=True)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# sdg_flow_GLC_GATE_UP = sdg_flow_GLC_GATE_UP['value']\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# sdg_flow_GLC_FLOW_FISH = full_data['GLC']['flow_data']['value']\u001b[39;00m\n\u001b[0;32m     10\u001b[0m vel \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 11\u001b[0m full_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGLC\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_vel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdg_flow_GLC_FLOW_FISH\u001b[49m\u001b[43m,\u001b[49m\u001b[43msdg_flow_GLC_GATE_UP\u001b[49m\u001b[43m,\u001b[49m\u001b[43mglc_bottom_elev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglc_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# full_data[\"MID\"]['vel'] = calc_vel(sdg_flow_MID_FLOW_FISH,sdg_flow_MID_GATE_UP,mid_bottom_elev, mid_width)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# full_data[\"OLD\"]['vel'] = calc_vel(sdg_flow_OLD_FLOW_FISH,sdg_flow_OLD_GATE_UP,old_bottom_elev, old_width)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# vel['MID'] = calc_vel(sdg_flow.MID_FLOW_FISH,sdg_flow.MID_GATE_UP,gatef['bottom_elev'][1], gatef['width'][1] )\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# vel['OLD'] = calc_vel(sdg_flow.OLD_FLOW_FISH,sdg_flow.OLD_GATE_UP,gatef['bottom_elev'][2], gatef['width'][2] )\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(full_data[\"GLC\"]['vel'].tail())\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(full_data\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Cell \u001b[1;32mIn[132], line 4\u001b[0m, in \u001b[0;36mcalc_vel\u001b[1;34m(flow, stage_up, bottom_elev, width)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_vel\u001b[39m(flow,stage_up, bottom_elev, width):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#velocity is flow/cross-section\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     xs \u001b[38;5;241m=\u001b[39m (\u001b[43mstage_up\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbottom_elev\u001b[49m)\u001b[38;5;241m*\u001b[39mwidth\n\u001b[0;32m      5\u001b[0m     vel \u001b[38;5;241m=\u001b[39m flow\u001b[38;5;241m/\u001b[39mxs\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vel\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:7913\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7910\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   7912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 7913\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:7945\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7942\u001b[0m right \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(right)\n\u001b[0;32m   7943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[0;32m   7944\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[1;32m-> 7945\u001b[0m     bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[38;5;241m=\u001b[39mbm\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   7948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Inigo\\Projects\\sdg-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1441\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(other):\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;66;03m# This check must come after the check for np.timedelta64\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;66;03m# as is_integer returns True for these\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[1;32m-> 1441\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m integer_op_not_supported(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1442\u001b[0m     obj \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeriodArray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1443\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_addsub_int_array_or_scalar(other \u001b[38;5;241m*\u001b[39m obj\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39m_n, operator\u001b[38;5;241m.\u001b[39msub)\n",
      "\u001b[1;31mTypeError\u001b[0m: Addition/subtraction of integers and integer-arrays with DatetimeArray is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`"
     ]
    }
   ],
   "source": [
    "thr_vel = 8\n",
    "# mask = (sdg_flow.index.month>=5) & (sdg_flow.index.month<12) # time when gate are in operation\n",
    "# vel=pd.DataFrame()\n",
    "sdg_flow_GLC_FLOW_FISH.set_index('datetime', inplace=True)\n",
    "sdg_flow_GLC_FLOW_FISH = sdg_flow_GLC_FLOW_FISH['value']\n",
    "# print(sdg_flow_GLC_FLOW_FISH.head())\n",
    "# sdg_flow_GLC_GATE_UP.set_index('datetime', inplace=True)\n",
    "# sdg_flow_GLC_GATE_UP = sdg_flow_GLC_GATE_UP['value']\n",
    "# sdg_flow_GLC_FLOW_FISH = full_data['GLC']['flow_data']['value']\n",
    "vel = pd.DataFrame()\n",
    "full_data[\"GLC\"]['vel'] = calc_vel(sdg_flow_GLC_FLOW_FISH,sdg_flow_GLC_GATE_UP,glc_bottom_elev, glc_width)\n",
    "# full_data[\"MID\"]['vel'] = calc_vel(sdg_flow_MID_FLOW_FISH,sdg_flow_MID_GATE_UP,mid_bottom_elev, mid_width)\n",
    "# full_data[\"OLD\"]['vel'] = calc_vel(sdg_flow_OLD_FLOW_FISH,sdg_flow_OLD_GATE_UP,old_bottom_elev, old_width)\n",
    "\n",
    "# vel['MID'] = calc_vel(sdg_flow.MID_FLOW_FISH,sdg_flow.MID_GATE_UP,gatef['bottom_elev'][1], gatef['width'][1] )\n",
    "# vel['OLD'] = calc_vel(sdg_flow.OLD_FLOW_FISH,sdg_flow.OLD_GATE_UP,gatef['bottom_elev'][2], gatef['width'][2] )\n",
    "# print(full_data[\"GLC\"]['vel'].tail())\n",
    "print(full_data.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
